{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:26:03.884332: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-08 09:26:04.091679: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-08 09:26:04.094211: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 09:26:08.884006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Conv2D,Conv2DTranspose, Dropout, Reshape, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data importing and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv', header=None)\n",
    "\n",
    "\n",
    "df = df.values.reshape(60, 64, 64, 1)\n",
    "\n",
    "labels = np.zeros(60)\n",
    "\n",
    "x_real_train, x_real_test = train_test_split(df, test_size=0.2) #12 test values\n",
    "y_real_train, y_real_test = train_test_split(labels, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create points in latent space to be fed into generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_generator_input():\n",
    "    input = np.random.normal(3,2.5,size=(1,100))\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(60*8*8, input_shape=(100,)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Reshape((8,8,60)))\n",
    "    \n",
    "    model.add(Conv2DTranspose(1, (1,1), strides=(2,2), padding='same', input_shape=(8,8,60)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "  \n",
    "    \n",
    "    model.add(Conv2DTranspose(1, (1,1), strides=(2,2), padding='same', input_shape=(16,16,60)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Conv2DTranspose(1, (1,1), strides=(2,2), padding='same', input_shape=(32,32,60)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "              \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_discriminator():\n",
    "    \n",
    "    # 1st set of layers\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, (5,5), strides=(2,2), padding=\"same\", input_shape=(64,64,1)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(256, (5,5), strides=(2,2), padding='same'))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "  \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1)) # Binary classification (2 outputs), so only 1 dense layer needed\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create the models from the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 3840)              387840    \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 3840)              0         \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 8, 8, 60)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_18 (Conv2  (None, 16, 16, 1)         61        \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 16, 16, 1)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_19 (Conv2  (None, 32, 32, 1)         2         \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 32, 32, 1)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_20 (Conv2  (None, 64, 64, 1)         2         \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 64, 64, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387905 (1.48 MB)\n",
      "Trainable params: 387905 (1.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "tf.Tensor(\n",
      "[[[[0.4317087]\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   ...\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]]\n",
      "\n",
      "  [[0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   ...\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]]\n",
      "\n",
      "  [[0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   ...\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   ...\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]]\n",
      "\n",
      "  [[0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   ...\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]]\n",
      "\n",
      "  [[0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   ...\n",
      "   [0.       ]\n",
      "   [0.       ]\n",
      "   [0.       ]]]], shape=(1, 64, 64, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "gen_model = make_generator()\n",
    "\n",
    "noise = generate_generator_input()\n",
    "generated_map = gen_model(noise, training = False)\n",
    "\n",
    "print(generated_map)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, test the untrained discriminator on the map of noise generated before\n",
    "Negative values means fake, positive means real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 128)       3328      \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 65537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 888321 (3.39 MB)\n",
      "Trainable params: 888321 (3.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "tf.Tensor([[0.00025942]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "disc_model = make_discriminator()\n",
    "decision = disc_model(generated_map)\n",
    "print(decision)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator loss, adapted from: https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrim_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(np.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(np.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(np.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = Adam(1e-4)\n",
    "disc_optimizer = Adam(1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "\n",
    "VERBOSE = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(current_batch):\n",
    "    \n",
    "    noise_sample = generate_generator_input()\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "\n",
    "        generated_map = gen_model(noise_sample, training=True)\n",
    "\n",
    "        real_output = disc_model(current_batch, training=True)\n",
    "        fake_output = disc_model(generated_map,  training = True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output=fake_output)\n",
    "        disc_loss = discrim_loss(real_output=real_output, fake_output=fake_output)\n",
    "\n",
    "        \n",
    "\n",
    "    gen_gradients = gen_tape.gradient(gen_loss, gen_model.trainable_variables)\n",
    "    disc_gradients = disc_tape.gradient(disc_loss, disc_model.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(gen_gradients, gen_model.trainable_variables))\n",
    "    disc_optimizer.apply_gradients(zip(disc_gradients, disc_model.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, N_EPOCHS):\n",
    "\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "    \n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        for map_batch in dataset:\n",
    "            print(map_batch.shape)\n",
    "            gen_loss, disc_loss = training_step(map_batch)\n",
    "\n",
    "            gen_losses.append(gen_loss)\n",
    "            disc_losses.append(disc_loss)\n",
    "    \n",
    "    input_for_map_after_training = generate_generator_input()\n",
    "    map_after_training = gen_model(input_for_map_after_training, training=False)\n",
    "\n",
    "    print(map_after_training)\n",
    "\n",
    "    return gen_losses, disc_losses\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 64, 64, 1)\n",
      "(64, 64, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_104781/3602859254.py\", line 10, in training_step  *\n        generated_map.reshape(1,64,64)\n\n    AttributeError: Tensor object has no attribute 'reshape'. \n            If you are looking for numpy-related methods, please run the following:\n            from tensorflow.python.ops.numpy_ops import np_config\n            np_config.enable_numpy_behavior()\n          \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(x_real_train\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m gen_losses, disc_losses \u001b[39m=\u001b[39m train(x_real_train, N_EPOCHS)\n\u001b[1;32m      5\u001b[0m \u001b[39m# issue with flattening in discrim, \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[84], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, N_EPOCHS)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m map_batch \u001b[39min\u001b[39;00m dataset:\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(map_batch\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m     gen_loss, disc_loss \u001b[39m=\u001b[39m training_step(map_batch)\n\u001b[1;32m     13\u001b[0m     gen_losses\u001b[39m.\u001b[39mappend(gen_loss)\n\u001b[1;32m     14\u001b[0m     disc_losses\u001b[39m.\u001b[39mappend(disc_loss)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filetxryhpql.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__training_step\u001b[0;34m(current_batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m gen_tape, ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m disc_tape:\n\u001b[1;32m     12\u001b[0m     generated_map \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(gen_model), (ag__\u001b[39m.\u001b[39mld(noise_sample),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[0;32m---> 13\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39;49mld(generated_map)\u001b[39m.\u001b[39;49mreshape, (\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(current_batch)\u001b[39m.\u001b[39mreshape, (\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m     real_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(disc_model), (ag__\u001b[39m.\u001b[39mld(current_batch),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_104781/3602859254.py\", line 10, in training_step  *\n        generated_map.reshape(1,64,64)\n\n    AttributeError: Tensor object has no attribute 'reshape'. \n            If you are looking for numpy-related methods, please run the following:\n            from tensorflow.python.ops.numpy_ops import np_config\n            np_config.enable_numpy_behavior()\n          \n"
     ]
    }
   ],
   "source": [
    "print(x_real_train.shape)\n",
    "\n",
    "gen_losses, disc_losses = train(x_real_train, N_EPOCHS)\n",
    "\n",
    "# issue with flattening in discrim, flatten is not flattening for the final dense layer. I don't know why this is the case.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'disc_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epoch_list \u001b[39m=\u001b[39m [\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,N_EPOCHS)]\n\u001b[0;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(disc_losses, epoch_list, \u001b[39m'\u001b[39m\u001b[39mr-\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(gen_losses, epoch_list, \u001b[39m'\u001b[39m\u001b[39mb-\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mGen and Disc loss over epochs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'disc_losses' is not defined"
     ]
    }
   ],
   "source": [
    "epoch_list = [range(0,N_EPOCHS)]\n",
    "plt.plot(disc_losses, epoch_list, 'r-')\n",
    "plt.plot(gen_losses, epoch_list, 'b-')\n",
    "plt.title('Gen and Disc loss over epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
